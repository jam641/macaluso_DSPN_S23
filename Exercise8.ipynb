{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szkkhiCZDF52"
      },
      "source": [
        "# Exercise 8:  Linear models, continued\n",
        "\n",
        "This homework assignment is designed to give you a deeper understanding of linear models. First, we'll dive into the math behind the closed-form solution of maximum likelihood estimation. **In the first section below, write your answers using Latex equation formatting.**\n",
        "\n",
        "*Note: Check out [this page](https://gtribello.github.io/mathNET/assets/notebook-writing.html) and [this page](https://towardsdatascience.com/write-markdown-latex-in-the-jupyter-notebook-10985edb91fd) for resources on how to do Latex formatting. You can also double click on the question cells in this notebook to see how math is formatted in the questions.*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJscNReoylRt"
      },
      "source": [
        "---\n",
        "## 1. Deriving the Maximum Likelihood Estimate for Simple Linear Regression (6 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nH82gwuymPi0"
      },
      "source": [
        "Using the mean squared error (MSE) as your objective function (the thing you're trying to minimize when you fit your model) allows for a closed form solution to finding the maximum likelihood estimate (MLE) of your model parameters in linear regression. Let’s consider the simple, single predictor variable model, i.e. simple linear regression :  $Y= \\beta_0 + \\beta_1 X $. \n",
        "\n",
        "a) Use algebra to show how you can expand out $MSE(\\beta_0, \\beta_1)$ to get from i to ii below.\n",
        "\n",
        "> _i)_ $E[ (Y-(\\beta_0 + \\beta_1 X))^2]$\n",
        "\n",
        "> _ii)_ $E[Y^2] -2 \\beta_0E[Y]-2 \\beta_1 Cov[X,Y]-2 \\beta_1 E[X]E[Y]+ \\beta_0^2 +2 \\beta_0 \\beta_1 E[X]+\\beta_1^2 Var[X]+ \\beta_1^2 (E[X])^2$\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dn2hveNho-Of"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "> _step 1)_ $E[ (Y-(\\beta_0 + \\beta_1 X))^2]$ \n",
        "\n",
        "> _step 2)_ $E[Y^2] -2\\beta_0E[Y] -2\\beta_1E[XY] +E[(\\beta_0+\\beta_1X)^2]$ \n",
        "\n",
        "> _step 3)_ $E[Y^2] -2\\beta_0E[Y] -2\\beta_1(Cov[XY] + E[X]E[Y]) + \\beta_0^2 + 2\\beta_0\\beta_1E[X] + \\beta_1^2E[X^2]$\n",
        "\n",
        "> _step 4)_ $E[Y^2] -2 \\beta_0E[Y]-2 \\beta_1 Cov[X,Y]-2 \\beta_1 E[X]E[Y]+ \\beta_0^2 +2 \\beta_0 \\beta_1 E[X]+\\beta_1^2 Var[X]+ \\beta_1^2 (E[X])^2$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCr46r9xwRXP"
      },
      "source": [
        "b) Prove that the MLE of $\\beta_0$ is $E[Y]- \\beta_1 E[X]$ by taking the derivative of _ii_ above, with respect to $\\beta_0$, setting the derivative to zero, and solving for $\\beta_0$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ul-PZyLbwTCQ"
      },
      "source": [
        "**Answer:**\n",
        "* Here is our initial equation:  \n",
        "$E[Y^2] -2 \\beta_0E[Y]-2 \\beta_1 Cov[X,Y]-2 \\beta_1 E[X]E[Y]+ \\beta_0^2 +2 \\beta_0 \\beta_1 E[X]+\\beta_1^2 (Var[X])+ \\beta_1^2 (E[X])^2$\n",
        "\n",
        "* I'm dropping the following terms from the equation (I'm going to focus on the $\\beta_0$ terms since that will allow me to solve for $\\beta_0$.):\n",
        "$E[Y^2]$, $-2 \\beta_1 Cov[X,Y]$ , $-2 \\beta_1 E[X]E[Y]$ , $\\beta_1^2 (Var[X])$ , $\\beta_1^2 (E[X])^2$\n",
        "\n",
        "* Remaining terms I'm starting with while taking the derivatives (aka taking the derivative focusing on $\\beta_0$): $-2 \\beta_0E[Y] + \\beta_0^2 +2 \\beta_0 \\beta_1 E[X]$\n",
        "\n",
        "_step 1)_ $-2 \\beta_0E[Y] + \\beta_0^2 +2 \\beta_0 \\beta_1 E[X]$\n",
        "\n",
        "_step 2)_ $-2 \\beta_0^1E[Y]$ + $(2 * \\beta_0^{2-1})$ + $2 \\beta_0^1 \\beta_1E[X]$\n",
        "\n",
        "_step 3)_ $(1 * -2 \\beta_0^{1-1}E[Y])$ + $(2 * \\beta_0^1)$ + $(1 * 2 \\beta_0^{1-1} \\beta_1 E[X])$\n",
        "\n",
        "_step 4)_  $(1 * -2\\beta_0^0E[Y])$ + $2\\beta_0$ + $(1 * 2\\beta_0^0 \\beta_1 E[X])$\n",
        "\n",
        "_step 5)_ $(1 * -2 * E[Y])$ + $2\\beta_0$ + $2 \\beta_1E[X]$\n",
        "\n",
        "_step 6)_ $-2E[Y]$ + $2\\beta_0$ + $2 \\beta_1E[X]$\n",
        "\n",
        "$f(\\beta_0) = -2E[Y] + 2\\beta_0 + 2 \\beta_1E[X]$\n",
        "\n",
        "* Now I'll set $f(\\beta_0)$ equal to zero so I can actually solve for $\\beta_0$ \n",
        "\n",
        "_step 1)_ $0 = -2E[Y] + 2\\beta_0 + 2 \\beta_1E[X]$\n",
        "\n",
        "_step 2)_ $0 = 2(-E[Y] + \\beta_0 + \\beta_1E[X])$\n",
        "\n",
        "_step 3)_ $0/2 = (2(-E[Y] + \\beta_0 + \\beta_1E[X]))/2$\n",
        "\n",
        "_step 4)_ $0 = -E[Y] + \\beta_0 + \\beta_1 E[X]$\n",
        "\n",
        "_step 5)_ $0 - \\beta_0 = -E[Y] + \\beta_0 - \\beta_0 + \\beta_1 E[X]$\n",
        "\n",
        "_step 6)_ $-\\beta_0 = -E[Y] + \\beta_1 E[X]$\n",
        "\n",
        "_step 7)_ $(-\\beta_0)/-1 = (-E[Y] + \\beta_1 E[X])/-1$\n",
        "\n",
        "_step 8)_ $\\beta_0 = E[Y] - \\beta_1 E[X]$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uv4Z7afw4gB"
      },
      "source": [
        "c) Prove that the MLE for $\\beta_1$ is $Cov[X,Y]/Var[X]$ by taking the derivative of equation _ii_ above, with respect to $\\beta_1$, setting the derivative to zero, and solving for $\\beta_1$. *Hint: after you've simplified / expanded a bit, plug in the solution for $\\beta_0$ from part b.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWTFZ6ZSw6sh"
      },
      "source": [
        "**Answer:**\n",
        "* Here is our initial equation again:  \n",
        "$E[Y^2] -2 \\beta_0E[Y]-2 \\beta_1 Cov[X,Y]-2 \\beta_1 E[X]E[Y]+ \\beta_0^2 +2 \\beta_0 \\beta_1 E[X]+\\beta_1^2 (Var[X])+ \\beta_1^2 (E[X])^2$\n",
        "\n",
        "* I'm dropping the following terms from the equation (I'm going to focus on the $\\beta_1$ terms since that will allow me to solve for $\\beta_1$.):\n",
        "$E[Y^2]$, $-2 \\beta_0 E[Y]$, $\\beta_0^2$\n",
        "\n",
        "* Remaining terms I'm starting with while taking the derivatives (aka taking the derivative focusing on $\\beta_1$): $-2 \\beta_1 Cov(X,Y) -2 \\beta_1E[X]E[Y] +2 \\beta_0 \\beta_1E[X] + \\beta_1^2 Var(X) + \\beta_1^2 E[X]^2$ \n",
        "\n",
        "_step 1)_ $-2 \\beta_1 Cov(X,Y) - 2 \\beta1 E[X] E[Y] + 2 \\beta_0 \\beta_1 E[X] + \\beta_1^2 Var(X) + \\beta_1^2E[X]^2$\n",
        "\n",
        "_step 2)_ $-2\\beta_1^1Cov(X,Y)$ + $-2 \\beta_1^1 E[X] E[Y]$ + $2 \\beta_0 \\beta_1^1 E[X]$ + $2 \\beta_1^{2-1} Var(X)$ + $2 \\beta_1^{2-1} E[X]^2$\n",
        "\n",
        "_step 3)_ $(1 * -2 \\beta_1^{1-1} Cov(X,Y))$ + $(1 * -2 \\beta_1^{1-1} E[X]E[Y])$ + $(1 * 2 \\beta_0 \\beta_1^{1-1} E[X])$ + $2 \\beta_1^1 Var(X)$ + $2 \\beta_1^1 E[X]^2$\n",
        "\n",
        "_step 4)_ $(1 * -2 \\beta_1^0 Cov (X,Y))$ + $(1 * -2 \\beta_1^0 E[X] E[Y])$ + $(1 * 2 \\beta_0 \\beta_1^0 E[X])$ + $2 \\beta_1 Var(X)$ + $2 \\beta_1 E[X]^2$\n",
        "\n",
        "_step 5)_ $-2Cov(X,Y)$ + $(-2E[X]E[Y])$ + $2 \\beta_0 E[X]$ + $2 \\beta_1 Var(X)$ + $2 \\beta_1 E[X]^2$\n",
        "\n",
        "_step 6)_ $-2Cov(X,Y)$ - $2E[X]E[Y]$ + $2 \\beta_0 E[X]$ + $2 \\beta_1 Var(X)$ + $2 \\beta_1 E[X]^2$\n",
        "\n",
        "$f(\\beta_1) = -2Cov(X,Y) -2E[X]E[Y] + 2 \\beta_0 E[X] +2 \\beta_1Var(X) +2 \\beta_1E[(X)]^2$\n",
        "\n",
        "* Now I will plug in my $\\beta_0$ derivative, then distribute the $2E[X]$ of the third term in the equation:\n",
        "\n",
        "$f(\\beta_1) = -2Cov(X,Y) -2E[X]E[Y] +2E[X]E[Y] -2 \\beta_1 E[X]^2 + 2 \\beta_1 Var(X) + 2 \\beta_1 E[X]^2$\n",
        "\n",
        "* By doing some more algebra, I can reduce my equation down to:\n",
        "\n",
        "$f(\\beta_1) = -2Cov(X,Y) + 2 \\beta_1Var(X)$\n",
        "\n",
        "* Now I'll set $f(\\beta_1)$ equal to zero so I can actually solve for $\\beta_1$ \n",
        "\n",
        "_step 1)_ $0 = -2Cov(X,Y) +2 \\beta_1 Var(X)$\n",
        "\n",
        "_step 2)_ $0 = 2(-Cov(X,Y) + \\beta_1 Var(X))$\n",
        "\n",
        "_step 3)_ $(0)/2 = (2(-Cov(X,Y) + \\beta_1 Var(X)))/2$\n",
        "\n",
        "_step 4)_ $0 + Cov(X,Y) = -Cov(X,Y) + Cov(X,Y) + \\beta_1 Var(X)$\n",
        "\n",
        "_step 5)_ $Cov(X,Y) = \\beta_1 Cov(X,Y)$\n",
        "\n",
        "_step 6)_ $(Cov(X,Y))/Var(X) = (\\beta_1 Cov(X,Y))/Var(X)$\n",
        "\n",
        "_step 7)_ $(Cov(X,Y))/(Var(X))= \\beta_1$\n",
        "\n",
        "_step 8)_ $\\beta_1 = Cov(X,Y)/Var(X)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66X264ZpDF58"
      },
      "source": [
        "---\n",
        "## 2. Connecting to data (4 points)\n",
        "\n",
        "Now let's connect this to some real data. Once again we'll be using the  **unrestricted_trimmed_1_7_2020_10_50_44.csv** file from the *Homework/hcp_data* folder in the class GitHub repository. \n",
        "\n",
        "​\n",
        "This data is a portion of the [Human Connectome Project database](http://www.humanconnectomeproject.org/). It provides measures of cognitive tasks and brain morphology measurements from 1206 participants. The full description of each variable is provided in the **HCP_S1200_DataDictionary_April_20_2018.csv** file in the *Homework/hcp_data* folder in the class GitHub repository. \n",
        "\n",
        "a) Use the `setwd` and `read.csv` functions to load data from the **unrestricted_trimmed_1_7_2020_10_50_44.csv** file. Then use the `tidyverse` tools make a new dataframe `d1` that only inclues the subject ID (`Subject`), Flanker Task performance (`Flanker_Unadj`), and total grey matter volume (`FS_Total_GM_Vol`) variables and remove all _NA_ values.\n",
        "\n",
        "Use the `head` function to look at the first few rows of each data frame. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PZ0lngBjDF58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f10151dd-6b6e-4956-9e0c-6231ac1142b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1mRows: \u001b[22m\u001b[34m1206\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m500\u001b[39m\n",
            "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
            "\u001b[1mDelimiter:\u001b[22m \",\"\n",
            "\u001b[31mchr\u001b[39m   (64): Release, Acquisition, Gender, Age, NEORAW_01, NEORAW_02, NEORAW_...\n",
            "\u001b[32mdbl\u001b[39m  (434): Subject, MMSE_Score, PSQI_Score, PSQI_Comp1, PSQI_Comp2, PSQI_Co...\n",
            "\u001b[34mtime\u001b[39m   (2): PSQI_BedTime, PSQI_GetUpTime\n",
            "\n",
            "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
            "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A tibble: 6 × 500</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>Subject</th><th scope=col>Release</th><th scope=col>Acquisition</th><th scope=col>Gender</th><th scope=col>Age</th><th scope=col>MMSE_Score</th><th scope=col>PSQI_Score</th><th scope=col>PSQI_Comp1</th><th scope=col>PSQI_Comp2</th><th scope=col>PSQI_Comp3</th><th scope=col>⋯</th><th scope=col>Noise_Comp</th><th scope=col>Odor_Unadj</th><th scope=col>Odor_AgeAdj</th><th scope=col>PainIntens_RawScore</th><th scope=col>PainInterf_Tscore</th><th scope=col>Taste_Unadj</th><th scope=col>Taste_AgeAdj</th><th scope=col>Mars_Log_Score</th><th scope=col>Mars_Errs</th><th scope=col>Mars_Final</th></tr>\n",
              "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>⋯</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>100004</td><td>S900</td><td>Q06</td><td>M</td><td>22-25</td><td>29</td><td>8</td><td>1</td><td>2</td><td>2</td><td>⋯</td><td>5.2</td><td>101.12</td><td> 86.45</td><td>2</td><td>45.9</td><td>107.17</td><td>105.31</td><td>1.80</td><td>0</td><td>1.80</td></tr>\n",
              "\t<tr><td>100206</td><td>S900</td><td>Q11</td><td>M</td><td>26-30</td><td>30</td><td>6</td><td>1</td><td>1</td><td>1</td><td>⋯</td><td>6.0</td><td>108.79</td><td> 97.19</td><td>1</td><td>49.7</td><td> 72.63</td><td> 72.03</td><td>1.84</td><td>0</td><td>1.84</td></tr>\n",
              "\t<tr><td>100307</td><td>Q1  </td><td>Q01</td><td>F</td><td>26-30</td><td>29</td><td>4</td><td>1</td><td>0</td><td>1</td><td>⋯</td><td>3.6</td><td>101.12</td><td> 86.45</td><td>0</td><td>38.6</td><td> 71.69</td><td> 71.76</td><td>1.76</td><td>0</td><td>1.76</td></tr>\n",
              "\t<tr><td>100408</td><td>Q3  </td><td>Q03</td><td>M</td><td>31-35</td><td>30</td><td>4</td><td>1</td><td>1</td><td>0</td><td>⋯</td><td>2.0</td><td>108.79</td><td> 98.04</td><td>2</td><td>52.6</td><td>114.01</td><td>113.59</td><td>1.76</td><td>2</td><td>1.68</td></tr>\n",
              "\t<tr><td>100610</td><td>S900</td><td>Q08</td><td>M</td><td>26-30</td><td>30</td><td>4</td><td>1</td><td>1</td><td>0</td><td>⋯</td><td>2.0</td><td>122.25</td><td>110.45</td><td>0</td><td>38.6</td><td> 84.84</td><td> 85.31</td><td>1.92</td><td>1</td><td>1.88</td></tr>\n",
              "\t<tr><td>101006</td><td>S500</td><td>Q06</td><td>F</td><td>31-35</td><td>28</td><td>2</td><td>1</td><td>1</td><td>0</td><td>⋯</td><td>6.0</td><td>122.25</td><td>111.41</td><td>0</td><td>38.6</td><td>123.80</td><td>123.31</td><td>1.80</td><td>0</td><td>1.80</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA tibble: 6 × 500\n\n| Subject &lt;dbl&gt; | Release &lt;chr&gt; | Acquisition &lt;chr&gt; | Gender &lt;chr&gt; | Age &lt;chr&gt; | MMSE_Score &lt;dbl&gt; | PSQI_Score &lt;dbl&gt; | PSQI_Comp1 &lt;dbl&gt; | PSQI_Comp2 &lt;dbl&gt; | PSQI_Comp3 &lt;dbl&gt; | ⋯ ⋯ | Noise_Comp &lt;dbl&gt; | Odor_Unadj &lt;dbl&gt; | Odor_AgeAdj &lt;dbl&gt; | PainIntens_RawScore &lt;dbl&gt; | PainInterf_Tscore &lt;dbl&gt; | Taste_Unadj &lt;dbl&gt; | Taste_AgeAdj &lt;dbl&gt; | Mars_Log_Score &lt;dbl&gt; | Mars_Errs &lt;dbl&gt; | Mars_Final &lt;dbl&gt; |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n| 100004 | S900 | Q06 | M | 22-25 | 29 | 8 | 1 | 2 | 2 | ⋯ | 5.2 | 101.12 |  86.45 | 2 | 45.9 | 107.17 | 105.31 | 1.80 | 0 | 1.80 |\n| 100206 | S900 | Q11 | M | 26-30 | 30 | 6 | 1 | 1 | 1 | ⋯ | 6.0 | 108.79 |  97.19 | 1 | 49.7 |  72.63 |  72.03 | 1.84 | 0 | 1.84 |\n| 100307 | Q1   | Q01 | F | 26-30 | 29 | 4 | 1 | 0 | 1 | ⋯ | 3.6 | 101.12 |  86.45 | 0 | 38.6 |  71.69 |  71.76 | 1.76 | 0 | 1.76 |\n| 100408 | Q3   | Q03 | M | 31-35 | 30 | 4 | 1 | 1 | 0 | ⋯ | 2.0 | 108.79 |  98.04 | 2 | 52.6 | 114.01 | 113.59 | 1.76 | 2 | 1.68 |\n| 100610 | S900 | Q08 | M | 26-30 | 30 | 4 | 1 | 1 | 0 | ⋯ | 2.0 | 122.25 | 110.45 | 0 | 38.6 |  84.84 |  85.31 | 1.92 | 1 | 1.88 |\n| 101006 | S500 | Q06 | F | 31-35 | 28 | 2 | 1 | 1 | 0 | ⋯ | 6.0 | 122.25 | 111.41 | 0 | 38.6 | 123.80 | 123.31 | 1.80 | 0 | 1.80 |\n\n",
            "text/latex": "A tibble: 6 × 500\n\\begin{tabular}{lllllllllllllllllllll}\n Subject & Release & Acquisition & Gender & Age & MMSE\\_Score & PSQI\\_Score & PSQI\\_Comp1 & PSQI\\_Comp2 & PSQI\\_Comp3 & ⋯ & Noise\\_Comp & Odor\\_Unadj & Odor\\_AgeAdj & PainIntens\\_RawScore & PainInterf\\_Tscore & Taste\\_Unadj & Taste\\_AgeAdj & Mars\\_Log\\_Score & Mars\\_Errs & Mars\\_Final\\\\\n <dbl> & <chr> & <chr> & <chr> & <chr> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & ⋯ & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n\\hline\n\t 100004 & S900 & Q06 & M & 22-25 & 29 & 8 & 1 & 2 & 2 & ⋯ & 5.2 & 101.12 &  86.45 & 2 & 45.9 & 107.17 & 105.31 & 1.80 & 0 & 1.80\\\\\n\t 100206 & S900 & Q11 & M & 26-30 & 30 & 6 & 1 & 1 & 1 & ⋯ & 6.0 & 108.79 &  97.19 & 1 & 49.7 &  72.63 &  72.03 & 1.84 & 0 & 1.84\\\\\n\t 100307 & Q1   & Q01 & F & 26-30 & 29 & 4 & 1 & 0 & 1 & ⋯ & 3.6 & 101.12 &  86.45 & 0 & 38.6 &  71.69 &  71.76 & 1.76 & 0 & 1.76\\\\\n\t 100408 & Q3   & Q03 & M & 31-35 & 30 & 4 & 1 & 1 & 0 & ⋯ & 2.0 & 108.79 &  98.04 & 2 & 52.6 & 114.01 & 113.59 & 1.76 & 2 & 1.68\\\\\n\t 100610 & S900 & Q08 & M & 26-30 & 30 & 4 & 1 & 1 & 0 & ⋯ & 2.0 & 122.25 & 110.45 & 0 & 38.6 &  84.84 &  85.31 & 1.92 & 1 & 1.88\\\\\n\t 101006 & S500 & Q06 & F & 31-35 & 28 & 2 & 1 & 1 & 0 & ⋯ & 6.0 & 122.25 & 111.41 & 0 & 38.6 & 123.80 & 123.31 & 1.80 & 0 & 1.80\\\\\n\\end{tabular}\n",
            "text/plain": [
              "  Subject Release Acquisition Gender Age   MMSE_Score PSQI_Score PSQI_Comp1\n",
              "1 100004  S900    Q06         M      22-25 29         8          1         \n",
              "2 100206  S900    Q11         M      26-30 30         6          1         \n",
              "3 100307  Q1      Q01         F      26-30 29         4          1         \n",
              "4 100408  Q3      Q03         M      31-35 30         4          1         \n",
              "5 100610  S900    Q08         M      26-30 30         4          1         \n",
              "6 101006  S500    Q06         F      31-35 28         2          1         \n",
              "  PSQI_Comp2 PSQI_Comp3 ⋯ Noise_Comp Odor_Unadj Odor_AgeAdj PainIntens_RawScore\n",
              "1 2          2          ⋯ 5.2        101.12      86.45      2                  \n",
              "2 1          1          ⋯ 6.0        108.79      97.19      1                  \n",
              "3 0          1          ⋯ 3.6        101.12      86.45      0                  \n",
              "4 1          0          ⋯ 2.0        108.79      98.04      2                  \n",
              "5 1          0          ⋯ 2.0        122.25     110.45      0                  \n",
              "6 1          0          ⋯ 6.0        122.25     111.41      0                  \n",
              "  PainInterf_Tscore Taste_Unadj Taste_AgeAdj Mars_Log_Score Mars_Errs\n",
              "1 45.9              107.17      105.31       1.80           0        \n",
              "2 49.7               72.63       72.03       1.84           0        \n",
              "3 38.6               71.69       71.76       1.76           0        \n",
              "4 52.6              114.01      113.59       1.76           2        \n",
              "5 38.6               84.84       85.31       1.92           1        \n",
              "6 38.6              123.80      123.31       1.80           0        \n",
              "  Mars_Final\n",
              "1 1.80      \n",
              "2 1.84      \n",
              "3 1.76      \n",
              "4 1.68      \n",
              "5 1.88      \n",
              "6 1.80      "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A tibble: 6 × 3</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>Subject</th><th scope=col>Flanker_Unadj</th><th scope=col>FS_Total_GM_Vol</th></tr>\n",
              "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>100004</td><td>121.97</td><td>    NA</td></tr>\n",
              "\t<tr><td>100206</td><td>130.42</td><td>807245</td></tr>\n",
              "\t<tr><td>100307</td><td>112.56</td><td>664124</td></tr>\n",
              "\t<tr><td>100408</td><td>121.18</td><td>726206</td></tr>\n",
              "\t<tr><td>100610</td><td>126.53</td><td>762308</td></tr>\n",
              "\t<tr><td>101006</td><td>101.85</td><td>579632</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA tibble: 6 × 3\n\n| Subject &lt;dbl&gt; | Flanker_Unadj &lt;dbl&gt; | FS_Total_GM_Vol &lt;dbl&gt; |\n|---|---|---|\n| 100004 | 121.97 |     NA |\n| 100206 | 130.42 | 807245 |\n| 100307 | 112.56 | 664124 |\n| 100408 | 121.18 | 726206 |\n| 100610 | 126.53 | 762308 |\n| 101006 | 101.85 | 579632 |\n\n",
            "text/latex": "A tibble: 6 × 3\n\\begin{tabular}{lll}\n Subject & Flanker\\_Unadj & FS\\_Total\\_GM\\_Vol\\\\\n <dbl> & <dbl> & <dbl>\\\\\n\\hline\n\t 100004 & 121.97 &     NA\\\\\n\t 100206 & 130.42 & 807245\\\\\n\t 100307 & 112.56 & 664124\\\\\n\t 100408 & 121.18 & 726206\\\\\n\t 100610 & 126.53 & 762308\\\\\n\t 101006 & 101.85 & 579632\\\\\n\\end{tabular}\n",
            "text/plain": [
              "  Subject Flanker_Unadj FS_Total_GM_Vol\n",
              "1 100004  121.97            NA         \n",
              "2 100206  130.42        807245         \n",
              "3 100307  112.56        664124         \n",
              "4 100408  121.18        726206         \n",
              "5 100610  126.53        762308         \n",
              "6 101006  101.85        579632         "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A tibble: 6 × 3</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>Subject</th><th scope=col>Flanker_Unadj</th><th scope=col>FS_Total_GM_Vol</th></tr>\n",
              "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>100206</td><td>130.42</td><td>807245</td></tr>\n",
              "\t<tr><td>100307</td><td>112.56</td><td>664124</td></tr>\n",
              "\t<tr><td>100408</td><td>121.18</td><td>726206</td></tr>\n",
              "\t<tr><td>100610</td><td>126.53</td><td>762308</td></tr>\n",
              "\t<tr><td>101006</td><td>101.85</td><td>579632</td></tr>\n",
              "\t<tr><td>101107</td><td>107.04</td><td>665024</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA tibble: 6 × 3\n\n| Subject &lt;dbl&gt; | Flanker_Unadj &lt;dbl&gt; | FS_Total_GM_Vol &lt;dbl&gt; |\n|---|---|---|\n| 100206 | 130.42 | 807245 |\n| 100307 | 112.56 | 664124 |\n| 100408 | 121.18 | 726206 |\n| 100610 | 126.53 | 762308 |\n| 101006 | 101.85 | 579632 |\n| 101107 | 107.04 | 665024 |\n\n",
            "text/latex": "A tibble: 6 × 3\n\\begin{tabular}{lll}\n Subject & Flanker\\_Unadj & FS\\_Total\\_GM\\_Vol\\\\\n <dbl> & <dbl> & <dbl>\\\\\n\\hline\n\t 100206 & 130.42 & 807245\\\\\n\t 100307 & 112.56 & 664124\\\\\n\t 100408 & 121.18 & 726206\\\\\n\t 100610 & 126.53 & 762308\\\\\n\t 101006 & 101.85 & 579632\\\\\n\t 101107 & 107.04 & 665024\\\\\n\\end{tabular}\n",
            "text/plain": [
              "  Subject Flanker_Unadj FS_Total_GM_Vol\n",
              "1 100206  130.42        807245         \n",
              "2 100307  112.56        664124         \n",
              "3 100408  121.18        726206         \n",
              "4 100610  126.53        762308         \n",
              "5 101006  101.85        579632         \n",
              "6 101107  107.04        665024         "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Read in Original Data\n",
        "library (readr)\n",
        "urlfile=\"https://raw.githubusercontent.com/CoAxLab/DataSciencePsychNeuro/master/Homework%20datasets/hcp_data/unrestricted_trimmed_1_7_2020_10_50_44.csv\"\n",
        "hcp <- read_csv(url(urlfile))\n",
        "head(hcp)\n",
        "\n",
        "# Make new dataframe\n",
        "library(tidyverse)\n",
        "data <- hcp %>% select(Subject, Flanker_Unadj, FS_Total_GM_Vol)\n",
        "head(data)\n",
        "\n",
        "# Remove all NAs\n",
        "d1 <- drop_na(data)\n",
        "head(d1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3owDQ0U2Ewn"
      },
      "source": [
        "b) Now we're going to see if the solutions we proved above actually line up with the model fit that R gives us (it should...). Calculate what the $\\beta_0$ and $\\beta_1$ coefficients should be for a simple linear regression model using `Flanker_Unadj` as $Y$ and `FS_Total_GM_Vol` as $X$. Use the formulas we derived above ($\\beta_1 = Cov[XY]/Var[X]$ , $\\beta_0 = E[Y] - \\beta_1E[X]$). Then use `lm()` to compare the coefficients you calculated with the ones R gives you. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "mWvD8shRDF5_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "b3b3c62a-d5bd-4895-c39c-475b7ab62ee8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "3.10996547106463e-05"
            ],
            "text/markdown": "3.10996547106463e-05",
            "text/latex": "3.10996547106463e-05",
            "text/plain": [
              "[1] 3.109965e-05"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "90.2564608190943"
            ],
            "text/markdown": "90.2564608190943",
            "text/latex": "90.2564608190943",
            "text/plain": [
              "[1] 90.25646"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm(formula = Flanker_Unadj ~ FS_Total_GM_Vol, data = d1)\n",
              "\n",
              "Residuals:\n",
              "     Min       1Q   Median       3Q      Max \n",
              "-28.2280  -6.5969  -0.0119   6.5497  31.0108 \n",
              "\n",
              "Coefficients:\n",
              "                 Estimate Std. Error t value Pr(>|t|)    \n",
              "(Intercept)     9.026e+01  3.041e+00  29.677  < 2e-16 ***\n",
              "FS_Total_GM_Vol 3.110e-05  4.412e-06   7.048 3.18e-12 ***\n",
              "---\n",
              "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
              "\n",
              "Residual standard error: 9.864 on 1111 degrees of freedom\n",
              "Multiple R-squared:  0.0428,\tAdjusted R-squared:  0.04194 \n",
              "F-statistic: 49.68 on 1 and 1111 DF,  p-value: 3.177e-12\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Creating our x and y\n",
        "x <- d1$FS_Total_GM_Vol\n",
        "y <- d1$Flanker_Unadj\n",
        "\n",
        "# Creating our cov(X,Y) and our var(X)\n",
        "CovXY <- mean((x-mean(x))*(y-mean(y)))\n",
        "VarX <- mean((x-mean(x))^2)\n",
        "\n",
        "# calculating beta_1\n",
        "  # beta_1 = Cov[XY]/Var[X]\n",
        "beta_1 = ((CovXY)/(VarX))\n",
        "beta_1 # 3.10996547106463e-05 ~ 3.11e-05\n",
        "\n",
        "# calculating beta_0\n",
        "  # beta_1 = E[Y]-beta_1E[X]\n",
        "beta_0 = mean(y)-(beta_1 * (mean(x)))\n",
        "beta_0 # 90.2564608190943 ~ 90.26\n",
        "\n",
        "# linear model\n",
        "model1 <- lm(Flanker_Unadj ~ FS_Total_GM_Vol, d1) #build model\n",
        "summary(model1) #look at summary output\n",
        "  # beta_0 aka our intercept = 9.026e+01 ~ 90.26\n",
        "  # beta_1 aka out FS_Total_GM_Vol = 3.110e-05 ~ 3.11e-05\n",
        "# yep our beta_0 and beta_1 match!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcnXbsZvDF6B"
      },
      "source": [
        "**DUE:** 5pm EST, March 1, 2023"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aG5swCweDF6B"
      },
      "source": [
        "**IMPORTANT** Did you collaborate with anyone on this assignment? If so, list their names here. \n",
        "> *Sara Jaramillo*"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "4.2.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}